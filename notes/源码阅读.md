# Zookeeper连接

当系统启动时，首先做的便是zookeeper的连接，这一步在ZookeeperRegistryCenter的init方法中完成，源码精简为:

```java
@Override
public void init() {
    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()
            .connectString(zkConfig.getServerLists())
            .namespace(zkConfig.getNamespace());
    
    client = builder.build();
    client.start();

    int maxWaitTime = zkConfig.getMaxSleepTimeMilliseconds() * zkConfig.getMaxRetries();
    if (!client.blockUntilConnected(maxWaitTime, TimeUnit.MILLISECONDS)) {
            
        client.close();
        throw new KeeperException.OperationTimeoutException();
    }
}
```

代码很简单，这里使用了Apache Curator。

# 初始化

## JobScheduler

JobScheduler是elastic-job-lite中核心的对象，负责job的注册、启动等。代码分布在其构造器和init方法中，下面根据功能点进行说明。

## Job实例创建

```java
private JobScheduler(final CoordinatorRegistryCenter regCenter, 
                     final LiteJobConfiguration liteJobConfig, 
                     final JobEventBus jobEventBus, 
                     final ElasticJobListener... elasticJobListeners) {
    JobRegistry.getInstance().addJobInstance(
        liteJobConfig.getJobName(), new JobInstance()
    );
}
```

### JobRegistry

这货是负责本地各种任务相关的映射信息，下面是其类图：

![JobRegistry](images/job_registry.png)

addJobInstance便是将初始化的任务信息放到jobInstanceMap中。JobInstance中包含了任务的String类型的唯一ID，其生成方法:

```java
public JobInstance() {
	jobInstanceId = IpUtils.getIp() + DELIMITER + 
            ManagementFactory.getRuntimeMXBean().getName().split("@")[0];
}
```

所以：**ID由IP + 进程号的方式组成**。

## ElasticJobListener

elastic-job留下的允许我们监控任务的启动和结束的接口：

![ElasticJobListener](images/elastic_job_listener.png)

## GuaranteeService

前面说的Job实例创建只是本地的对象操作，尚未与zookeeper有交互。GuaranteeService从作者的角度来说叫做

> 保证分布式任务全部开始和结束状态的服务.

但是个人觉着更准确来说是**封装了任务节点的数据访问和配置**。如下：

![GuaranteeService](images/guarantee_service.png)

JobScheduler构造器通过调用setGuaranteeServiceForElasticJobListeners方法创建了一个此对象：

```java
private void setGuaranteeServiceForElasticJobListeners(final CoordinatorRegistryCenter regCenter, 
                                                       final List<ElasticJobListener> elasticJobListeners) {
    GuaranteeService guaranteeService = new GuaranteeService(regCenter, liteJobConfig.getJobName());
    for (ElasticJobListener each : elasticJobListeners) {
        if (each instanceof AbstractDistributeOnceElasticJobListener) {
            ((AbstractDistributeOnceElasticJobListener) each).setGuaranteeService(guaranteeService);
        }
    }
}
```

此对象最终只能被AbstractDistributeOnceElasticJobListener(只执行一次的监听器)引用到。

## 门面

### 调度器

即SchedulerFacade类，其构造器创建了一大坨Service:

```java
public SchedulerFacade(final CoordinatorRegistryCenter regCenter, final String jobName, final List<ElasticJobListener> elasticJobListeners) {
    this.jobName = jobName;
    configService = new ConfigurationService(regCenter, jobName);
    leaderService = new LeaderService(regCenter, jobName);
    serverService = new ServerService(regCenter, jobName);
    instanceService = new InstanceService(regCenter, jobName);
    shardingService = new ShardingService(regCenter, jobName);
    executionService = new ExecutionService(regCenter, jobName);
    monitorService = new MonitorService(regCenter, jobName);
    reconcileService = new ReconcileService(regCenter, jobName);
    listenerManager = new ListenerManager(regCenter, jobName, elasticJobListeners);
}
```

估计后续的操作都要依赖于这些Service完成。

### Job

即LiteJobFacade，也有一坨Service:

```java
public LiteJobFacade(final CoordinatorRegistryCenter regCenter, final String jobName, final List<ElasticJobListener> elasticJobListeners, 
                     final JobEventBus jobEventBus) {
    configService = new ConfigurationService(regCenter, jobName);
    shardingService = new ShardingService(regCenter, jobName);
    executionContextService = new ExecutionContextService(regCenter, jobName);
    executionService = new ExecutionService(regCenter, jobName);
    failoverService = new FailoverService(regCenter, jobName);
    this.elasticJobListeners = elasticJobListeners;
    this.jobEventBus = jobEventBus;
}
```

# 注册

从这里便开始与zookeeper有交互了。

## 任务配置

即:

```java
public void init() {
    LiteJobConfiguration liteJobConfigFromRegCenter = schedulerFacade.updateJobConfiguration(liteJobConfig);
}
```

这里的逻辑可以概括为：

1. 如果ZK上此任务已经存在(比如重启)并且没有启用覆盖，那么将以ZK的配置为准。
2. 否则以本地为准。

SchedulerFacade.updateJobConfiguration:

```java
public LiteJobConfiguration updateJobConfiguration(final LiteJobConfiguration liteJobConfig) {
	configService.persist(liteJobConfig);
	return configService.load(false);
}
```

persist方法实现:

```java
public void persist(final LiteJobConfiguration liteJobConfig) {
    checkConflictJob(liteJobConfig);
    if (!jobNodeStorage.isJobNodeExisted(ConfigurationNode.ROOT) || liteJobConfig.isOverwrite()) {
        jobNodeStorage.replaceJobNode(ConfigurationNode.ROOT, LiteJobConfigurationGsonFactory.toJson(liteJobConfig));
    }
}
```

zookeeper的存储结构如下:

![ZK结构](images/elastic_job_zk_structure.png)

config节点保存的数据其实就是LiteJobConfiguration对象序列化后得到的JSON串，如下图：

![配置结构](images/config_zk_data.png)

## Quartz调度器

elastic-job本地基于Quartz实现，这一步便是创建一个Quartz调度器，实现位于JobScheduler的init方法:

```java
JobScheduleController jobScheduleController = new JobScheduleController(
    createScheduler(), createJobDetail(liteJobConfigFromRegCenter.getTypeConfig().getJobClass()), 
    liteJobConfigFromRegCenter.getJobName()
);
```

核心为createScheduler方法:

```java
private Scheduler createScheduler() {
    Scheduler result;
    try {
        StdSchedulerFactory factory = new StdSchedulerFactory();
        factory.initialize(getBaseQuartzProperties());
        result = factory.getScheduler();
      result.getListenerManager().addTriggerListener(schedulerFacade.newJobTriggerListener());
    } catch (final SchedulerException ex) {
        throw new JobSystemException(ex);
    }
    return result;
}
```

没啥好说的。

## 任务监听

这一步是启动对任务根路径的监听，在这里就是/elastic-job/simpleElasticJob:

```java
@Override
public void addCacheData(final String cachePath) {
    TreeCache cache = new TreeCache(client, cachePath);
    cache.start();
}
```

## 启动信息

SchedulerFacade.registerStartUpInfo:

```java
public void registerStartUpInfo(final boolean enabled) {
    listenerManager.startAllListeners();
    leaderService.electLeader();
    serverService.persistOnline(enabled);
    instanceService.persistOnline();
    shardingService.setReshardingFlag();
    monitorService.listen();
    if (!reconcileService.isRunning()) {
        reconcileService.startAsync();
    }
}
```

这里的信息量略大。

### 监听器

```java
public void startAllListeners() {
    electionListenerManager.start();
    shardingListenerManager.start();
    failoverListenerManager.start();
    monitorExecutionListenerManager.start();
    shutdownListenerManager.start();
    triggerListenerManager.start();
    rescheduleListenerManager.start();
    guaranteeListenerManager.start();
    jobNodeStorage.addConnectionStateListener(regCenterConnectionStateListener);
}
```

这些监听器负责对zookeeper节点数据变化的处理，后面再对这一部分详细展开。

### 选主

利用Curator选主的代码如下:

```java
public void executeInLeader(final String latchNode, final LeaderExecutionCallback callback) {
    try (LeaderLatch latch = new LeaderLatch(getClient(), jobNodePath.getFullPath(latchNode))) {
        latch.start();
        latch.await();
        callback.execute();
    } catch (final Exception ex) {
        handleException(ex);
    }
}
```

选主利用的是`/elastic-job/simpleElasticJob/leader/election/latch`节点，如果当前节点成为主节点，那么将任务ID保存到`/elastic-job/simpleElasticJob/leader/election/instance`节点，如下图:

![选主](images/leader_instance.png)

### Server上线

这一步是标记当前节点处于上线状态，其实就是建立一个如下节点，节点值为空串:

![上线](images/online.png)

### 任务上线

这一步建立了一个如下**临时**节点:

![实例上线](images/instance_online.png)

作用感觉和上面略有重叠，有待后续确认。

### 分片标记

指的是持久化节点`/elastic-job/simpleElasticJob/leader/sharding/necessary`，值为空，标志需要重新分片，具体作用后面确认。

### 调解服务

指的是ReconcileService会启动对节点`/elastic-job/simpleElasticJob/config`的监听，前面提到过，此节点保存的是任务的配置JSON，调解的原理后面再详细介绍。

# 启动

位于JobScheduler.init:

```java
public void init() {
  jobScheduleController.scheduleJob(liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getCron());
}
```

这里其实就是在本地启动了Quartz去执行:

```java
public void scheduleJob(final String cron) {
    if (!scheduler.checkExists(jobDetail.getKey())) {
        scheduler.scheduleJob(jobDetail, createTrigger(cron));
    }
    scheduler.start();
}
```





